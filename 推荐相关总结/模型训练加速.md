# 背景
随着模型参数和样本数量的增加，单节点上模型保存和训练时长出现挑战。我们这里主要讨论模型训练时间过长的问题。  
主要的解决方案是分布式训练和GPU优化

## 分布式  
分布式训练会把每个更新梯度的节点叫做worker。一般来说，按照worker数量，将参数更新的任务均分到不同的节点，每个节点只负责相应参数的梯度计算。

一般来说，分为两种模式：parameter server模式; all reduce.  
- parameter server模式下，parameter server负责整合梯度和更新模型参数，workers计算梯度.  
- all reduce模式下只有workers,worker之间相互同步整合梯度.

### parameter server模式

parameter server模式下主要分为同步和异步机制.  


| 模式 | 训练迭代| 优点| 缺点|
| -----| -----| ----| ---- | 
| 同步|  所有worker训练同一份batch sample，通过BP来获取各自对应参数的梯度，通信给parameter server；parameter server收集完所有workers的梯度后广播给所有workers再进行新一轮迭代| 梯度更加精准 | 更次迭代被最慢的节点限制| 
| 异步同上| parameter每次收集到1个worker的梯度就更新后广播给所有workers| 可以避免最慢节点的问题| 梯度计算不准确，通信开销更大  |
